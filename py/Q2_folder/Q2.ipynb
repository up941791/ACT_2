{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1986dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9426e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-02 13:52:23--  https://raw.githubusercontent.com/up941791/ACT_2/main/py/functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 143 [text/plain]\n",
      "Saving to: ‘functions.py’\n",
      "\n",
      "functions.py        100%[===================>]     143  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-02 13:52:23 (3.04 MB/s) - ‘functions.py’ saved [143/143]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing functions from functions.py. This gets them from GitHub.\n",
    "\n",
    "!wget -O functions.py https://raw.githubusercontent.com/up941791/ACT_2/main/py/functions.py\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acecbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
      "License(s): unknown\n",
      "Downloading cell-images-for-detecting-malaria.zip to /content\n",
      "100% 672M/675M [00:02<00:00, 258MB/s] \n",
      "100% 675M/675M [00:02<00:00, 238MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = 'samhedley'\n",
    "os.environ['KAGGLE_KEY'] = 'KGAT_b7cd8b87cb2a0346ef10f-b182f099721'\n",
    "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223b47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./cell_images\" # Directory for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6f6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset paths into training, validation, and test set paths\n",
    "def split_dataset_paths(folder_path, test_size, val_size):\n",
    "\n",
    "    split_paths = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "    for label in ['Parasitized', 'Uninfected']: # Looping through both classes\n",
    "        imgs = [] # List to hold valid image paths\n",
    "        class_dir = os.path.join(folder_path, label) # Directory for the current class\n",
    "        for img_name in os.listdir(class_dir): # Looping through images in the class directory\n",
    "            img_path = os.path.join(class_dir, img_name) # Full path to the image\n",
    "            \n",
    "            imgs.append((img_path, label)) # Append image path and label\n",
    "\n",
    "        train_imgs, temp_imgs = train_test_split(imgs, test_size=test_size + val_size, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=test_size / (test_size + val_size), random_state=42)\n",
    "\n",
    "        split_paths['train'].extend(train_imgs)\n",
    "        split_paths['val'].extend(val_imgs)\n",
    "        split_paths['test'].extend(test_imgs)\n",
    "\n",
    "    return split_paths\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00aecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train, val, and test sets\n",
    "split_paths = split_dataset_paths(data_dir, test_size=0.15, val_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b81fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 19292\n",
      "Validation samples: 4134\n",
      "Test samples: 4134\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of samples in each split\n",
    "print(\"Training samples:\", len(split_paths['train']))\n",
    "print(\"Validation samples:\", len(split_paths['val']))\n",
    "print(\"Test samples:\", len(split_paths['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for each split\n",
    "train_df = fn.make_dataframe(split_paths, 'train')\n",
    "val_df = fn.make_dataframe(split_paths, 'val')\n",
    "test_df = fn.make_dataframe(split_paths, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a57e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19290 validated image filenames belonging to 2 classes.\n",
      "Found 4134 validated image filenames belonging to 2 classes.\n",
      "Found 4134 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 2 invalid image filename(s) in x_col=\"img_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up ImageDataGenerators for training, validation, and test sets\n",
    "\n",
    "target_size = (128, 128) # Target size for image resizing\n",
    "batch_size = 64 # Batch size for training and validation\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255) # Scaling pixel values to [0, 1]\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe( # Training data generator\n",
    "    train_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe( # Validation data generator\n",
    "    val_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe( # Test data generator\n",
    "    test_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a62df7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model checkpoints to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4992bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up learning rate reduction on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0b63768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up early stopping to stop if the model stops improving\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1bfe0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of callbacks to be used during training\n",
    "callbacks_list = [checkpoint, reduce_lr, earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the CNN model\n",
    "\n",
    "cNN = Sequential()\n",
    "\n",
    "cNN.add(Input(shape=(128, 128, 3)))\n",
    "cNN.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cNN.add(MaxPooling2D((2, 2)))\n",
    "cNN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cNN.add(MaxPooling2D((2, 2)))\n",
    "cNN.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cNN.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cNN.add(Flatten())\n",
    "cNN.add(Dense(64, activation='relu'))\n",
    "cNN.add(Dropout(0.5))\n",
    "\n",
    "cNN.add(Dense(1, activation='sigmoid'))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59628038",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = Adam(learning_rate=0.001) # Setting the optimiser\n",
    "\n",
    "cNN.compile(optimizer=optimiser, loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()]) # Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7334 - loss: 0.5214 - precision_2: 0.7226 - recall_2: 0.7231\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93445, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - accuracy: 0.7338 - loss: 0.5210 - precision_2: 0.7229 - recall_2: 0.7235 - val_accuracy: 0.9344 - val_loss: 0.1660 - val_precision_2: 0.9499 - val_recall_2: 0.9173 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9377 - loss: 0.1901 - precision_2: 0.9390 - recall_2: 0.9356\n",
      "Epoch 2: val_accuracy improved from 0.93445 to 0.95041, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 89ms/step - accuracy: 0.9377 - loss: 0.1900 - precision_2: 0.9390 - recall_2: 0.9356 - val_accuracy: 0.9504 - val_loss: 0.1454 - val_precision_2: 0.9355 - val_recall_2: 0.9676 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9502 - loss: 0.1577 - precision_2: 0.9443 - recall_2: 0.9563\n",
      "Epoch 3: val_accuracy improved from 0.95041 to 0.95525, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 90ms/step - accuracy: 0.9502 - loss: 0.1577 - precision_2: 0.9443 - recall_2: 0.9563 - val_accuracy: 0.9552 - val_loss: 0.1424 - val_precision_2: 0.9524 - val_recall_2: 0.9584 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9563 - loss: 0.1295 - precision_2: 0.9471 - recall_2: 0.9666\n",
      "Epoch 4: val_accuracy improved from 0.95525 to 0.95573, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.9563 - loss: 0.1295 - precision_2: 0.9471 - recall_2: 0.9666 - val_accuracy: 0.9557 - val_loss: 0.1494 - val_precision_2: 0.9345 - val_recall_2: 0.9802 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9595 - loss: 0.1197 - precision_2: 0.9520 - recall_2: 0.9679\n",
      "Epoch 5: val_accuracy improved from 0.95573 to 0.95767, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 88ms/step - accuracy: 0.9595 - loss: 0.1197 - precision_2: 0.9520 - recall_2: 0.9679 - val_accuracy: 0.9577 - val_loss: 0.1390 - val_precision_2: 0.9433 - val_recall_2: 0.9739 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9640 - loss: 0.1053 - precision_2: 0.9582 - recall_2: 0.9703\n",
      "Epoch 6: val_accuracy did not improve from 0.95767\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 89ms/step - accuracy: 0.9640 - loss: 0.1053 - precision_2: 0.9582 - recall_2: 0.9703 - val_accuracy: 0.9550 - val_loss: 0.1419 - val_precision_2: 0.9385 - val_recall_2: 0.9739 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9692 - loss: 0.0872 - precision_2: 0.9631 - recall_2: 0.9758\n",
      "Epoch 7: val_accuracy improved from 0.95767 to 0.95791, saving model to best_model.keras\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 93ms/step - accuracy: 0.9692 - loss: 0.0873 - precision_2: 0.9631 - recall_2: 0.9758 - val_accuracy: 0.9579 - val_loss: 0.1386 - val_precision_2: 0.9509 - val_recall_2: 0.9657 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9716 - loss: 0.0833 - precision_2: 0.9686 - recall_2: 0.9749\n",
      "Epoch 8: val_accuracy did not improve from 0.95791\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 89ms/step - accuracy: 0.9716 - loss: 0.0833 - precision_2: 0.9686 - recall_2: 0.9749 - val_accuracy: 0.9540 - val_loss: 0.1572 - val_precision_2: 0.9532 - val_recall_2: 0.9550 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9767 - loss: 0.0665 - precision_2: 0.9740 - recall_2: 0.9787\n",
      "Epoch 9: val_accuracy did not improve from 0.95791\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 88ms/step - accuracy: 0.9767 - loss: 0.0666 - precision_2: 0.9740 - recall_2: 0.9787 - val_accuracy: 0.9487 - val_loss: 0.1766 - val_precision_2: 0.9626 - val_recall_2: 0.9337 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9800 - loss: 0.0521 - precision_2: 0.9818 - recall_2: 0.9784\n",
      "Epoch 10: val_accuracy did not improve from 0.95791\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 88ms/step - accuracy: 0.9800 - loss: 0.0521 - precision_2: 0.9818 - recall_2: 0.9784 - val_accuracy: 0.9538 - val_loss: 0.1962 - val_precision_2: 0.9580 - val_recall_2: 0.9492 - learning_rate: 5.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9876 - loss: 0.0347 - precision_2: 0.9876 - recall_2: 0.9876\n",
      "Epoch 11: val_accuracy did not improve from 0.95791\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 89ms/step - accuracy: 0.9876 - loss: 0.0347 - precision_2: 0.9876 - recall_2: 0.9876 - val_accuracy: 0.9555 - val_loss: 0.2268 - val_precision_2: 0.9494 - val_recall_2: 0.9623 - learning_rate: 5.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9886 - loss: 0.0296 - precision_2: 0.9909 - recall_2: 0.9866\n",
      "Epoch 12: val_accuracy did not improve from 0.95791\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 90ms/step - accuracy: 0.9886 - loss: 0.0296 - precision_2: 0.9909 - recall_2: 0.9866 - val_accuracy: 0.9552 - val_loss: 0.2352 - val_precision_2: 0.9546 - val_recall_2: 0.9560 - learning_rate: 2.5000e-04\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "train = cNN.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4134/4134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9550 - loss: 0.1611 - precision_2: 0.9459 - recall_2: 0.9665\n",
      "Test Accuracy: 0.9533\n",
      "Test loss: 0.1539\n",
      "Test Recall: 0.9603\n",
      "Test Precision: 0.9470\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on the test set\n",
    "\n",
    "cNN.load_weights('best_model.keras') # Loading the best model weights\n",
    "\n",
    "test_loss, test_acc, precision, recall = cNN.evaluate(test_gen) # Evaluating on the test set\n",
    "\n",
    "# Printing test results\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
