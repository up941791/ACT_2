{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1986dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9426e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-02 13:09:17--  https://raw.githubusercontent.com/up941791/ACT_2/main/py/functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 143 [text/plain]\n",
      "Saving to: ‘functions.py’\n",
      "\n",
      "functions.py        100%[===================>]     143  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-02 13:09:17 (2.79 MB/s) - ‘functions.py’ saved [143/143]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing functions from functions.py. This gets them from GitHub.\n",
    "\n",
    "!wget -O functions.py https://raw.githubusercontent.com/up941791/ACT_2/main/py/functions.py\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acecbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
      "License(s): unknown\n",
      "Downloading cell-images-for-detecting-malaria.zip to /content\n",
      " 94% 637M/675M [00:03<00:00, 169MB/s] \n",
      "100% 675M/675M [00:03<00:00, 202MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = 'samhedley'\n",
    "os.environ['KAGGLE_KEY'] = 'KGAT_b7cd8b87cb2a0346ef10f-b182f099721'\n",
    "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223b47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./cell_images\" # Directory for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset paths into training, validation, and test set paths\n",
    "def split_dataset_paths(folder_path, test_size, val_size):\n",
    "\n",
    "    split_paths = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "    for label in ['Parasitized', 'Uninfected']: # Looping through both classes\n",
    "        imgs = [] # List to hold valid image paths\n",
    "        class_dir = os.path.join(folder_path, label) # Directory for the current class\n",
    "        for img_name in os.listdir(class_dir): # Looping through images in the class directory\n",
    "            img_path = os.path.join(class_dir, img_name) # Full path to the image\n",
    "            \n",
    "            imgs.append((img_path, label)) # Append image path and label\n",
    "\n",
    "        train_imgs, temp_imgs = train_test_split(imgs, test_size=test_size + val_size, random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=test_size / (test_size + val_size), random_state=42)\n",
    "\n",
    "        split_paths['train'].extend(train_imgs)\n",
    "        split_paths['val'].extend(val_imgs)\n",
    "        split_paths['test'].extend(test_imgs)\n",
    "\n",
    "    return split_paths\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00aecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train, val, and test sets\n",
    "split_paths = split_dataset_paths(data_dir, test_size=0.15, val_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b81fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 19292\n",
      "Validation samples: 4134\n",
      "Test samples: 4134\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of samples in each split\n",
    "print(\"Training samples:\", len(split_paths['train']))\n",
    "print(\"Validation samples:\", len(split_paths['val']))\n",
    "print(\"Test samples:\", len(split_paths['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for each split\n",
    "train_df = fn.make_dataframe(split_paths, 'train')\n",
    "val_df = fn.make_dataframe(split_paths, 'val')\n",
    "test_df = fn.make_dataframe(split_paths, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a57e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19291 validated image filenames belonging to 2 classes.\n",
      "Found 4133 validated image filenames belonging to 2 classes.\n",
      "Found 4134 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"img_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"img_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up ImageDataGenerators for training, validation, and test sets\n",
    "\n",
    "target_size = (128, 128) # Target size for image resizing\n",
    "batch_size = 64 # Batch size for training and validation\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255) # Scaling pixel values to [0, 1]\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe( # Training data generator\n",
    "    train_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe( # Validation data generator\n",
    "    val_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe( # Test data generator\n",
    "    test_df,\n",
    "    x_col='img_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62df7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model checkpoints to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4992bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up learning rate reduction on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    facotor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0b63768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up early stopping to stop if the model stops improving\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfe0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of callbacks to be used during training\n",
    "callbacks_list = [checkpoint, reduce_lr, earlystopping]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
